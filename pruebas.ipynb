{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LambdaFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.command.clean import clean\n",
    "from email.mime import image\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "import boto3\n",
    "import urllib\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ExifTags, ImageColor\n",
    "import base64\n",
    "\n",
    "\n",
    "\n",
    "def lambda_handler():\n",
    "    # TODO implement\n",
    "\n",
    "    # logger = logging.getLogger()\n",
    "    # logger.setLevel(logging.INFO)\n",
    "\n",
    "    # bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    # key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], encoding='utf-8')\n",
    "\n",
    "    bucket='analitica-rekognition-bucket'\n",
    "    key='caras.jpg'\n",
    "   \n",
    "    print('Llamada de crop')\n",
    "\n",
    "    dictionary, num, image= detect_faces(bucket,key)\n",
    "\n",
    "    print('\\n Resultado final: \\n')\n",
    "    print(dictionary)\n",
    "    print('número de personas: ' + '{0:.0f}'.format(num) + '\\n')\n",
    "\n",
    "    print('Llamada de crop')\n",
    "    listaimg=cropFace(image,dictionary,num,key)\n",
    "\n",
    "    for image in listaimg:\n",
    "\n",
    "        image_data = Image.open(io.BytesIO(image))\n",
    "        var = 'JPEG'\n",
    "        # image_data.save(r'C:\\Users\\user\\Desktop',var)\n",
    "        image_data.show()\n",
    "\n",
    "        #Se busca si la persona esta en una collection\n",
    "        #Se recibe un booleano donde true indica que si pertence y false que no pertenece\n",
    "        faceids=search_faces(image)\n",
    "\n",
    "        #Se actualiza atributo (Status) en la base de datos en DynamoDB\n",
    "        #de acuerdo al resultado de la función search_faces para cada una de las coincidencias en la collection\n",
    "        for faceid in faceids:\n",
    "            updateItemDB(faceid)\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "def detect_faces(bucket,key):\n",
    "\n",
    "    client=boto3.client('rekognition', 'us-east-1')\n",
    "\n",
    "\n",
    "    print(bucket)\n",
    "    print(key)\n",
    "    \n",
    "    response = client.detect_faces(Image={'S3Object': {'Bucket': bucket, 'Name': key}},\n",
    "        Attributes=['ALL'])\n",
    "\n",
    "    print('Detected faces for ' + key)   \n",
    "\n",
    "    for faceDetail in response['FaceDetails']:\n",
    "        print('The detected face is between ' + str(faceDetail['AgeRange']['Low']) \n",
    "            + ' and ' + str(faceDetail['AgeRange']['High']) + ' years old')\n",
    "\n",
    "        # print('Here are the other attributes:')\n",
    "        # print(json.dumps(faceDetail, indent=4, sort_keys=True))\n",
    "\n",
    "        # Access predictions for individual face details and print them\n",
    "        print(\"Gender: \" + str(faceDetail['Gender']))\n",
    "        # print(\"Smile: \" + str(faceDetail['Smile']))\n",
    "        # print(\"Eyeglasses: \" + str(faceDetail['Eyeglasses']))\n",
    "        # print(\"Emotions: \" + str(faceDetail['Emotions'][0]))\n",
    "\n",
    "\n",
    "    # Load image from S3 bucket\n",
    "    s3_connection = boto3.resource('s3')\n",
    "    s3_object = s3_connection.Object(bucket,key)\n",
    "    s3_response = s3_object.get()\n",
    "\n",
    "    \n",
    "\n",
    "    stream = io.BytesIO(s3_response['Body'].read())\n",
    "\n",
    "    print('Hasta aquí se ejecura sin PIL')\n",
    "    image=Image.open(stream)\n",
    "\n",
    "    imgWidth, imgHeight = image.size  \n",
    "\n",
    "    print('Se va a imprimir imagen')\n",
    "\n",
    "    # draw = ImageDraw.Draw(image)  \n",
    "                \n",
    "    dict={}\n",
    "\n",
    "\n",
    "    count=1\n",
    "\n",
    "    # calculate and display bounding boxes for each detected face       \n",
    "    # print('Bounding boxes for ' + key)    \n",
    "    for faceDetail in response['FaceDetails']:\n",
    "    \n",
    "\n",
    "        \n",
    "        box = faceDetail['BoundingBox']\n",
    "        left = imgWidth * box['Left']\n",
    "        top = imgHeight * box['Top']\n",
    "        width = imgWidth * box['Width']\n",
    "        height = imgHeight * box['Height']\n",
    "\n",
    "        dict['cara'+'{0:.0f}'.format(count)]=[left,top,left+width,top+height]\n",
    "                \n",
    "        count=count+1\n",
    "\n",
    "\n",
    "        print('Left: ' + '{0:.0f}'.format(left))\n",
    "        print('Top: ' + '{0:.0f}'.format(top))\n",
    "        print('Face Width: ' + \"{0:.0f}\".format(width))\n",
    "        print('Face Height: ' + \"{0:.0f}\".format(height))\n",
    "\n",
    "        points = (\n",
    "            (left,top),\n",
    "            (left + width, top),\n",
    "            (left + width, top + height),\n",
    "            (left , top + height),\n",
    "            (left, top)\n",
    "\n",
    "        )\n",
    "        # draw.line(points, fill='#00d400', width=2)\n",
    "\n",
    "    print('número de caras')\n",
    "    numCaras=len(response['FaceDetails'])\n",
    "\n",
    "\n",
    "    # image.show()\n",
    "\n",
    "    return dict, numCaras, image\n",
    "\n",
    "\n",
    "def cropFace(image,dict,numCaras,key):\n",
    "\n",
    "    client=boto3.client('s3')\n",
    "\n",
    "    key=key[0:len(key)-4]\n",
    "\n",
    "    listaimg=[]\n",
    "\n",
    "    for i in range(1,numCaras+1):\n",
    "        \n",
    "        nombre=key+\"{0:.0f}\".format(i)\n",
    "\n",
    "        dimensiones=dict['cara'+\"{0:.0f}\".format(i)]\n",
    "\n",
    "        dim=(int(dimensiones[0]),int(dimensiones[1]),int(dimensiones[2]),int(dimensiones[3]))\n",
    "        imagecrop=image.crop(dim)\n",
    "\n",
    "\n",
    "        img_byte_arr = io.BytesIO()\n",
    "\n",
    "\n",
    "        imagecrop.save(img_byte_arr, format=\"JPEG\")\n",
    "\n",
    "        # img_str = base64.b64encode(img_byte_arr.getvalue())\n",
    "\n",
    "        # imagecrop.save(img_byte_arr, format='JPEG')\n",
    "\n",
    "        image_file_size = img_byte_arr.tell()\n",
    "\n",
    "        print('Tamaño (bytes)')\n",
    "        print(image_file_size)\n",
    "\n",
    "        img_byte_arr = img_byte_arr.getvalue()\n",
    "\n",
    "        listaimg.append(img_byte_arr)\n",
    "\n",
    "    #     print(nombre+'.jpeg')\n",
    "\n",
    "    #     # client.upload_fileobj(img_str.read(), 'prueba-rekognition-analitica', nombre+'.jpeg')\n",
    "\n",
    "    #     client.put_object(\n",
    "    # Body=img_byte_arr,\n",
    "    # Bucket='prueba-rekognition-analitica',\n",
    "    # Key=nombre+'.jpeg',\n",
    "\n",
    "# )\n",
    "\n",
    "    print(len(listaimg))\n",
    "\n",
    "    return listaimg\n",
    "\n",
    "#Se define función para buscar caras en una imagen y relacionar con una collection\n",
    "#Recibe el nombre del bucket y de la imagen a analizar \n",
    "#Retorna lista con los FaceId de las coincidencias en la colección\n",
    "def search_faces(image):\n",
    "\n",
    "    #Cliente representando servicio de rekognition\n",
    "    client=boto3.client('rekognition', 'us-east-1')\n",
    "\n",
    "\n",
    "    collectionId = 'CollectionAnalitica' #Nombre de la colección\n",
    "    threshold = 80 #Umbral para similaridad entre caras\n",
    "    maxFaces = 100 #Número máximo de caras que quiere reconocer de la colección\n",
    "    \n",
    "    #Función del SDK (boto3) de python para buscar coincidencia con caras de una colección\n",
    "\n",
    "\n",
    "    response=client.search_faces_by_image(CollectionId=collectionId,\n",
    "                                    Image={'Bytes': image},\n",
    "                                    FaceMatchThreshold=threshold,\n",
    "                                     MaxFaces=maxFaces)\n",
    "\n",
    "\n",
    "    faceMatches = response['FaceMatches']\n",
    "\n",
    "    #Lista con el FaceId de la cara de coincidencia en la colección\n",
    "    listface=[]\n",
    "\n",
    "\n",
    "    for match in faceMatches:\n",
    "        print('FaceId:' + match['Face']['FaceId'])\n",
    "        print('ImageId:' + match['Face']['ImageId'])\n",
    "        print('Similarity: ' + \"{:.2f}\".format(match['Similarity']) + \"%\")\n",
    "        print('Confidence: ' + str(match['Face']['Confidence']))\n",
    "\n",
    "        #Si la similaridad entre coincidencia es mayor a 80% se agrega el FaceId a la lista listface\n",
    "        if match['Similarity'] > 80.0:\n",
    "            listface.append( match['Face']['FaceId'])\n",
    "\n",
    "    return listface\n",
    "\n",
    "\n",
    "#Se define función para actualizar un item de la base de datos de dynamodb\n",
    "#Recibe el FaceId del item a actualizar\n",
    "def updateItemDB(FaceId):\n",
    "\n",
    "    #Cliente representando servicio dynamodb\n",
    "    client = boto3.client('dynamodb')\n",
    "\n",
    "    try:\n",
    "\n",
    "        #Se actualiza la base de datos cambiando el atributo status con el valor booleano True\n",
    "        response = client.update_item(\n",
    "            TableName='rekognition-machine-analitic',\n",
    "            Key={\n",
    "                'FaceID': {\n",
    "                    'S': FaceId\n",
    "                }\n",
    "            },\n",
    "            AttributeUpdates={\n",
    "                'Status': {\n",
    "                    'Value': {\n",
    "                        'S': 'OK'\n",
    "                    },\n",
    "                    'Action': 'PUT'\n",
    "                }\n",
    "            },\n",
    "\n",
    "\n",
    "        )   \n",
    "\n",
    "        print('Actualizó DB')\n",
    "\n",
    "    except Exception as msg:\n",
    "\n",
    "        print(f\"Oops, no se pudo actualizar el item: {msg}\")\n",
    "\n",
    "lambda_handler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "notification = \"Here is the SNS notification for Lambda function tutorial.\"\n",
    "client = boto3.client('sns')\n",
    "\n",
    "response = client.publish (\n",
    "    TargetArn = \"arn:aws:sns:us-east-1:533886999211:SNSPrueba\",\n",
    "    Message = json.dumps({'default': notification}),\n",
    "    MessageStructure = 'json'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "client = boto3.client('sns')\n",
    "\n",
    "snsArn = 'arn:aws:sns:us-east-1:533886999211:FaceSNS'\n",
    "message = \"This is a test notification.\"\n",
    "\n",
    "response = client.publish(\n",
    "    TopicArn = snsArn,\n",
    "    Message = message ,\n",
    "    Subject='Hello'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.get_item(\n",
    "    TableName='string',\n",
    "    Key={\n",
    "        'string': {\n",
    "            'S': 'string',\n",
    "            'N': 'string',\n",
    "            'B': b'bytes',\n",
    "            'SS': [\n",
    "                'string',\n",
    "            ],\n",
    "            'NS': [\n",
    "                'string',\n",
    "            ],\n",
    "            'BS': [\n",
    "                b'bytes',\n",
    "            ],\n",
    "            'M': {\n",
    "                'string': {'... recursive ...'}\n",
    "            },\n",
    "            'L': [\n",
    "                {'... recursive ...'},\n",
    "            ],\n",
    "            'NULL': True|False,\n",
    "            'BOOL': True|False\n",
    "        }\n",
    "    },\n",
    "    AttributesToGet=[\n",
    "        'string',\n",
    "    ],\n",
    "    ConsistentRead=True|False,\n",
    "    ReturnConsumedCapacity='INDEXES'|'TOTAL'|'NONE',\n",
    "    ProjectionExpression='string',\n",
    "    ExpressionAttributeNames={\n",
    "        'string': 'string'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800.0\n",
      "1080.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(\"rtsp://192.168.1.16:554/live1s1.sdp\",cv2.CAP_FFMPEG)\n",
    "\n",
    " #Tamaño de la imagen transmitida\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH )\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "print(width)\n",
    "print(height)\n",
    "\n",
    "#Se ajusta tamaño de la recepción de acuerdo al tamaño de\n",
    "#la imagen del video transmitido.\n",
    "cap.set(3, width)\n",
    "cap.set(4, height)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Cannot open RTSP stream')\n",
    "    exit(-1)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    cv2.namedWindow(\"RTSP stream\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('RTSP stream', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leyo bien\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "with open(\"/home/analitica2/analitica2/20220921_155031M.jpg\", \"rb\") as img_file:\n",
    "    if img_file.read():\n",
    "        print(\"leyo bien\")\n",
    "        print((base64.b64encode(img_file.read()).decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [x] Sent '{\"path\": \"/home/analitica2/Documentos/ftp/20220922_073004M.jpg\"}'\n",
      "Se envio imagen\n"
     ]
    }
   ],
   "source": [
    "import pika\n",
    "import json\n",
    "#método para públicar\n",
    "def publish(message, queue, mqHost):\n",
    "\n",
    "    #Se establece conexión con el servidor\n",
    "    connection = pika.BlockingConnection(pika.ConnectionParameters(mqHost))\n",
    "\n",
    "    #Se comienza el canal de comunicación\n",
    "    channel = connection.channel()\n",
    "\n",
    "    #Se establece la cola\n",
    "    channel.queue_declare(queue, passive=False, durable=False, exclusive=False, auto_delete=False, arguments=None)\n",
    "\n",
    "    #Se envía mensaje\n",
    "    channel.basic_publish(\"\", queue, bytes(message, 'utf-8'), properties=None, mandatory=False)\n",
    "    print(\" [x] Sent %r\" % message)\n",
    "\n",
    "    #Se cierra la conexión\n",
    "    connection.close()\n",
    "\n",
    "data = {}\n",
    "            \n",
    "data[\"path\"] = \"/home/analitica2/Documentos/ftp/20220922_073004M.jpg\"\n",
    "mqHost = \"localhost\"   \n",
    "\n",
    "#Se envía mensaje a la cola del servicio de mensajería\n",
    "publish(json.dumps(data), \"captured-image-queue\", mqHost)\n",
    "\n",
    "print(\"Se envio imagen\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"Records\":[{\"eventVersion\":\"2.1\",\"eventSource\":\"aws:s3\",\"awsRegion\":\"us-east-1\",\"eventTime\":\"2022-10-10T11:46:51.538Z\",\"eventName\":\"ObjectCreated:Put\",\"userIdentity\":{\"principalId\":\"A2RRAKSSN6SOYW\"},\"requestParameters\":{\"sourceIPAddress\":\"179.32.28.230\"},\"responseElements\":{\"x-amz-request-id\":\"PPF94S9K5PY231C0\",\"x-amz-id-2\":\"+hUloFhsu8lbc8s8pKEHNzI9MrBF/dWuQnO5YIaNSYd50Bc+aRKYQVsPpXPzOeFyH1hdWLVkBMw98qvW+koDwIrVYPE9lnrwwEZK8IIWsPg=\"},\"s3\":{\"s3SchemaVersion\":\"1.0\",\"configurationId\":\"kinesis_captures\",\"bucket\":{\"name\":\"bucket-gstreamer\",\"ownerIdentity\":{\"principalId\":\"A2RRAKSSN6SOYW\"},\"arn\":\"arn:aws:s3:::bucket-gstreamer\"},\"object\":{\"key\":\"20221078569343373.jpg\",\"size\":265525,\"eTag\":\"f9a6d0e79122ee2c9ad59032db67e1c1\",\"sequencer\":\"006344062B6C9901B9\"}}}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE COLLECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating collection:CollectionKinesis\n",
      "Collection ARN: aws:rekognition:us-east-1:853702706419:collection/CollectionKinesis\n",
      "Status code: 200\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "#Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#PDX-License-Identifier: MIT-0 (For details, see https://github.com/awsdocs/amazon-rekognition-developer-guide/blob/master/LICENSE-SAMPLECODE.)\n",
    "\n",
    "import boto3\n",
    "\n",
    "def create_collection(collection_id):\n",
    "\n",
    "    client=boto3.client('rekognition')\n",
    "\n",
    "    #Create a collection\n",
    "    print('Creating collection:' + collection_id)\n",
    "    response=client.create_collection(CollectionId=collection_id)\n",
    "    print('Collection ARN: ' + response['CollectionArn'])\n",
    "    print('Status code: ' + str(response['StatusCode']))\n",
    "    print('Done...')\n",
    "    \n",
    "def main():\n",
    "    collection_id='CollectionKinesis'\n",
    "    create_collection(collection_id)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for selene1.jpg\n",
      "Faces indexed:\n",
      "  Face ID: 2e2debd8-c79d-4d2f-925b-b40311a27ee4\n",
      "  Location: {'Width': 0.22858935594558716, 'Height': 0.24755693972110748, 'Left': 0.3399488031864166, 'Top': 0.48553362488746643}\n",
      "Faces not indexed:\n",
      "Faces indexed count: 1\n"
     ]
    }
   ],
   "source": [
    "#Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#PDX-License-Identifier: MIT-0 (For details, see https://github.com/awsdocs/amazon-rekognition-developer-guide/blob/master/LICENSE-SAMPLECODE.)\n",
    "\n",
    "import boto3\n",
    "\n",
    "def add_faces_to_collection(bucket,photo,collection_id):\n",
    "\n",
    "\n",
    "    \n",
    "    client=boto3.client('rekognition')\n",
    "\n",
    "    response=client.index_faces(CollectionId=collection_id,\n",
    "                                Image={'S3Object':{'Bucket':bucket,'Name':photo}},\n",
    "                                ExternalImageId=photo,\n",
    "                                MaxFaces=1,\n",
    "                                QualityFilter=\"AUTO\",\n",
    "                                DetectionAttributes=['ALL'])\n",
    "\n",
    "    print ('Results for ' + photo) \t\n",
    "    print('Faces indexed:')\t\t\t\t\t\t\n",
    "    for faceRecord in response['FaceRecords']:\n",
    "         print('  Face ID: ' + faceRecord['Face']['FaceId'])\n",
    "         print('  Location: {}'.format(faceRecord['Face']['BoundingBox']))\n",
    "\n",
    "    print('Faces not indexed:')\n",
    "    for unindexedFace in response['UnindexedFaces']:\n",
    "        print(' Location: {}'.format(unindexedFace['FaceDetail']['BoundingBox']))\n",
    "        print(' Reasons:')\n",
    "        for reason in unindexedFace['Reasons']:\n",
    "            print('   ' + reason)\n",
    "    return len(response['FaceRecords'])\n",
    "\n",
    "def main():\n",
    "    bucket='bucket-collection-kinesis'\n",
    "    collection_id='CollectionKinesis'\n",
    "    photo='selene1.jpg'\n",
    "    \n",
    "    \n",
    "    indexed_faces_count=add_faces_to_collection(bucket, photo, collection_id)\n",
    "    print(\"Faces indexed count: \" + str(indexed_faces_count))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List faces in a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faces in collection CollectionKinesis\n",
      "{'FaceId': '014c8443-2594-46d3-bd61-659a27a7790c', 'BoundingBox': {'Width': 0.23402300477027893, 'Height': 0.23601199686527252, 'Left': 0.2742139995098114, 'Top': 0.45376500487327576}, 'ImageId': 'a6eace65-70cc-326c-b284-17b37b91c661', 'ExternalImageId': 'selene.jpg', 'Confidence': 99.99949645996094, 'IndexFacesModelVersion': '6.0'}\n",
      "{'FaceId': '2e2debd8-c79d-4d2f-925b-b40311a27ee4', 'BoundingBox': {'Width': 0.2285889983177185, 'Height': 0.24755699932575226, 'Left': 0.33994901180267334, 'Top': 0.48553401231765747}, 'ImageId': '1af1596f-e68d-30d9-b8fb-56e6fa4ca2b0', 'ExternalImageId': 'selene1.jpg', 'Confidence': 99.99979400634766, 'IndexFacesModelVersion': '6.0'}\n",
      "{'FaceId': '6e9c1b59-0195-48fc-98bc-95fc7d2e3f16', 'BoundingBox': {'Width': 0.5574470162391663, 'Height': 0.6843469738960266, 'Left': 0.15246300399303436, 'Top': 0.09815199673175812}, 'ImageId': 'ef41e85a-4fee-3394-960e-f241079cf746', 'ExternalImageId': 'Emanuel2.jpg', 'Confidence': 99.99840545654297, 'IndexFacesModelVersion': '6.0'}\n",
      "{'FaceId': '8271b77d-77fc-4b57-a919-abfb5db5a904', 'BoundingBox': {'Width': 0.4637340009212494, 'Height': 0.5362420082092285, 'Left': 0.27566099166870117, 'Top': 0.12451999634504318}, 'ImageId': 'dfd9df3c-4549-34be-b024-af3b86e816ee', 'ExternalImageId': 'Emanuel.jpg', 'Confidence': 99.99949645996094, 'IndexFacesModelVersion': '6.0'}\n",
      "{'FaceId': 'af583a6d-d51c-4214-b296-4d25c5cd22bd', 'BoundingBox': {'Width': 0.4171060025691986, 'Height': 0.42915499210357666, 'Left': 0.3300809860229492, 'Top': 0.19499899446964264}, 'ImageId': 'c4d66bf3-679f-3e67-a619-005f6d794bb8', 'ExternalImageId': 'Emanuel3.jpg', 'Confidence': 99.9999008178711, 'IndexFacesModelVersion': '6.0'}\n",
      "faces count: 5\n"
     ]
    }
   ],
   "source": [
    "#Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#PDX-License-Identifier: MIT-0 (For details, see https://github.com/awsdocs/amazon-rekognition-developer-guide/blob/master/LICENSE-SAMPLECODE.)\n",
    "\n",
    "import boto3\n",
    "\n",
    "def list_faces_in_collection(collection_id):\n",
    "\n",
    "\n",
    "    maxResults=2\n",
    "    faces_count=0\n",
    "    tokens=True\n",
    "\n",
    "    client=boto3.client('rekognition')\n",
    "    response=client.list_faces(CollectionId=collection_id,\n",
    "                               MaxResults=maxResults)\n",
    "\n",
    "    print('Faces in collection ' + collection_id)\n",
    "\n",
    " \n",
    "    while tokens:\n",
    "\n",
    "        faces=response['Faces']\n",
    "\n",
    "        for face in faces:\n",
    "            print (face)\n",
    "            faces_count+=1\n",
    "        if 'NextToken' in response:\n",
    "            nextToken=response['NextToken']\n",
    "            response=client.list_faces(CollectionId=collection_id,\n",
    "                                       NextToken=nextToken,MaxResults=maxResults)\n",
    "        else:\n",
    "            tokens=False\n",
    "    return faces_count   \n",
    "def main():\n",
    "\n",
    "    collection_id='CollectionKinesis'\n",
    "\n",
    "    faces_count=list_faces_in_collection(collection_id)\n",
    "    print(\"faces count: \" + str(faces_count))\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
